<directory_structure>
.github/
  workflows/
    ci.yml
apple_capture/
  Sources/
    AppleCapture/
      CaptureSession.swift
      Encoder.swift
      FFIExports.swift
      FrameRingBuffer.swift
    AppleCaptureC/
      bridge.c
      bridge.h
    AppleCaptureTests/
      CaptureSessionTests.swift
  Package.swift
docs/
  architecture.md
  CONTRIBUTING.md
extension-host/
  sdk/
    index.d.ts
  src/
    index.ts
    ipc.ts
    loader.ts
    types.ts
  package.json
  tsconfig.json
mac_app/
  entitlements.plist
  Info.plist
recorder_cli/
  src/
    gui.rs
    lib.rs
    main.rs
  tests/
    bundle_build.rs
    bundle_dylib.rs
    gui_test.rs
    rpath_check.rs
  build.rs
  Cargo.toml
recorder_core/
  benches/
    capture_bench.rs
  src/
    tests/
      ffi_integration.rs
      ffi_smoke.rs
    ffi.rs
    lib.rs
  build.rs
  Cargo.toml
resources/
  tft.icns.placeholder
scripts/
  package_app.sh
.gitignore
Cargo.toml
package.json
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="apple_capture/Sources/AppleCapture/FFIExports.swift">
// ABOUTME: Swift FFI exports providing C-compatible functions for Rust integration
// ABOUTME: Uses @_cdecl to expose Swift functionality through C symbols

import Foundation

// Opaque pointer wrapper functions
private func retain(_ obj: AnyObject) -> UnsafeMutableRawPointer {
    Unmanaged.passRetained(obj).toOpaque()
}

private func fromOpaque(_ ptr: UnsafeMutableRawPointer) -> CaptureSession {
    Unmanaged<CaptureSession>.fromOpaque(ptr).takeUnretainedValue()
}

@_cdecl("swift_capture_create")
public func swift_capture_create() -> UnsafeMutableRawPointer? {
    retain(CaptureSession())
}

@_cdecl("swift_capture_start")
public func swift_capture_start(_ ptr: UnsafeMutableRawPointer?,
                                _ title: UnsafePointer<CChar>,
                                _ width: UInt32,
                                _ height: UInt32,
                                _ bitrate: UInt32,
                                _ outPath: UnsafePointer<CChar>) -> Bool {
    guard let ptr else { return false }
    let session = fromOpaque(ptr)
    let window = String(cString: title)
    let url = URL(fileURLWithPath: String(cString: outPath))
    
    var started = false
    let sema = DispatchSemaphore(value: 0)
    
    session.start(windowTitle: window,
                  width: Int(width),
                  height: Int(height),
                  bitrate: Int(bitrate),
                  outputURL: url) { error in
        // Error callback - signal failure
        print("Swift capture error: \(error.localizedDescription)")
        sema.signal()
    }
    
    // If no error arrives within 0.3s, assume success
    started = sema.wait(timeout: .now() + 0.3) == .timedOut
    return started
}

@_cdecl("swift_capture_stop")
public func swift_capture_stop(_ ptr: UnsafeMutableRawPointer?) {
    ptr.map { fromOpaque($0).stop() }
}

@_cdecl("swift_capture_destroy")
public func swift_capture_destroy(_ ptr: UnsafeMutableRawPointer?) {
    ptr.map { Unmanaged<CaptureSession>.fromOpaque($0).release() }
}
</file>

<file path="apple_capture/Sources/AppleCapture/FrameRingBuffer.swift">
// ABOUTME: Ring buffer for storing recent frames to enable rewind/replay features
// ABOUTME: Currently a placeholder for future instant-replay functionality

import Foundation
import CoreVideo

public final class FrameRingBuffer {
    private let capacity: Int
    private var buffer: [CVPixelBuffer?]
    private var writeIndex = 0
    private let lock = NSLock()
    
    public init(capacity: Int = 300) { // 5 seconds at 60fps
        self.capacity = capacity
        self.buffer = Array(repeating: nil, count: capacity)
    }
    
    public func append(_ pixelBuffer: CVPixelBuffer) {
        lock.lock()
        defer { lock.unlock() }
        
        // Release old buffer if present
        buffer[writeIndex] = nil
        
        // Store new buffer with retained reference
        buffer[writeIndex] = pixelBuffer
        writeIndex = (writeIndex + 1) % capacity
    }
    
    public func getFrames(last seconds: TimeInterval) -> [CVPixelBuffer] {
        lock.lock()
        defer { lock.unlock() }
        
        let frameCount = min(Int(seconds * 60), capacity)
        var frames: [CVPixelBuffer] = []
        
        for i in 0..<frameCount {
            let index = (writeIndex - 1 - i + capacity) % capacity
            if let frame = buffer[index] {
                frames.append(frame)
            }
        }
        
        return frames.reversed()
    }
    
    public func clear() {
        lock.lock()
        defer { lock.unlock() }
        
        buffer = Array(repeating: nil, count: capacity)
        writeIndex = 0
    }
}
</file>

<file path="apple_capture/Sources/AppleCaptureC/bridge.h">
#ifndef APPLE_CAPTURE_BRIDGE_H
#define APPLE_CAPTURE_BRIDGE_H

#include <stdbool.h>
#include <stdint.h>

#ifdef __cplusplus
extern "C" {
#endif

void* swift_capture_create(void);
bool swift_capture_start(void* cap,
                        const char* window_title,
                        uint32_t width,
                        uint32_t height,
                        uint32_t bitrate,
                        const char* output_path);
void swift_capture_stop(void* cap);
void swift_capture_destroy(void* cap);

#ifdef __cplusplus
}
#endif

#endif /* APPLE_CAPTURE_BRIDGE_H */
</file>

<file path="docs/architecture.md">
# Architecture

The TFT Recorder is designed as a modular, extensible screen recording system optimized for Team Fight Tactics gameplay capture on macOS.

## Overview

```
┌─────────────────┐     ┌──────────────────┐     ┌─────────────────┐
│   CLI (Rust)    │────▶│  Core (Rust)     │────▶│ Swift Capture   │
│  recorder bin   │     │  FFI Bridge      │     │  AVFoundation   │
└─────────────────┘     └──────────────────┘     └─────────────────┘
         │                                                 │
         │                                                 │
         ▼                                                 ▼
┌─────────────────┐                            ┌─────────────────┐
│ Extension Host  │                            │ Hardware H.264  │
│   (Node.js)     │                            │   Encoder       │
└─────────────────┘                            └─────────────────┘
```

## Core Components

### 1. Swift Capture Library (`apple_capture/`)

**Purpose**: Direct interface with macOS screen capture APIs

**Key Classes**:
- `CaptureSession`: Manages AVCaptureSession lifecycle
- `Encoder`: Hardware H.264 encoding via VideoToolbox
- `FrameRingBuffer`: Circular buffer for instant replay features

**Design Decisions**:
- Uses AVFoundation for maximum compatibility
- Hardware encoding to minimize CPU usage
- Direct CoreVideo buffer handling for zero-copy performance

### 2. Rust Core (`recorder_core/`)

**Purpose**: Safe FFI bridge and core recording logic

**Key Components**:
- FFI module: Manual C bindings to Swift (future: cxx for type safety)
- Recorder struct: Thread-safe recording state management
- Platform abstraction: Allows future Linux support

### 3. CLI Binary (`recorder_cli/`)

**Purpose**: User-facing command interface

**Subcommands**:
- `record`: Start recording with specified parameters
- `host`: Launch extension host (internal)
- `daemon`: Run as background service for IPC

### 4. Extension Host (`extension-host/`)

**Purpose**: VS Code-style plugin system

**Features**:
- Dynamic extension loading from `~/.tft-recorder/extensions/`
- gRPC IPC for recorder control
- Event-based activation (onRecordingStart, onCommand, etc.)
- TypeScript SDK for extension development

## Data Flow

1. **Recording Start**:
   ```
   CLI --[start cmd]--> Rust Core --[FFI]--> Swift --[AVCapture]--> Screen
   ```

2. **Frame Processing**:
   ```
   Screen --[CVPixelBuffer]--> Encoder --[H.264]--> MP4 Writer
                                  |
                                  └--[Ring Buffer]--> Extensions
   ```

3. **Extension Communication**:
   ```
   Extension <--[gRPC/Unix Socket]--> Daemon <--[Events]--> Recorder
   ```

## Key Design Principles

1. **Minimal Overhead**: Every component optimized for low latency
2. **Extensibility First**: Plugin architecture from day one
3. **Native Performance**: Platform-specific optimizations
4. **Type Safety**: Rust core with strong FFI contracts
5. **User Experience**: Simple CLI with sensible defaults

## Future Considerations

- **Linux Support**: Wayland capture via PipeWire
- **Windows Support**: Desktop Duplication API
- **GPU Encoding**: Metal/CUDA accelerated filters
- **Live Streaming**: RTMP output module
- **Cloud Sync**: Automatic highlight upload
</file>

<file path="docs/CONTRIBUTING.md">
# Contributing to TFT Recorder

Thank you for your interest in contributing! This document provides guidelines and instructions for contributing to the TFT Recorder project.

## Getting Started

1. Fork the repository
2. Clone your fork: `git clone https://github.com/yourusername/tft-recorder.git`
3. Create a feature branch: `git checkout -b feature/your-feature-name`
4. Make your changes
5. Run tests: `cargo test && swift test`
6. Submit a pull request

## Development Setup

### Prerequisites

- macOS 12.0+
- Xcode 14+ with command line tools
- Rust 1.79+ (`curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh`)
- Swift 5.10+
- Node.js 18+ (`brew install node`)

### Building

```bash
# Build everything
make all

# Or build components individually
cd apple_capture && swift build
cargo build --release
cd extension-host && npm install && npm run build
```

### Testing

```bash
# Run all tests
make test

# Or test individually
cargo test --workspace
cd apple_capture && swift test
cd extension-host && npm test
```

## Code Style

### Rust
- Follow standard Rust conventions
- Use `cargo fmt` before committing
- Run `cargo clippy` and fix warnings
- Document public APIs with `///` comments

### Swift
- Follow Swift API Design Guidelines
- Use SwiftLint configuration (if present)
- Document public APIs with `///` comments
- Prefer `guard` over nested `if` statements

### TypeScript
- Use ESLint configuration
- Prefer `const` over `let`
- Use async/await over callbacks
- Document exported functions with JSDoc

## Project Structure

```
tft-recorder/
├── recorder_core/      # Rust library (FFI bridge)
├── recorder_cli/       # Rust CLI binary
├── apple_capture/      # Swift screen capture
├── extension-host/     # Node.js plugin host
└── docs/              # Documentation
```

## Making Changes

### Adding Features

1. Discuss major features in an issue first
2. Keep changes focused and atomic
3. Update tests and documentation
4. Add entries to CHANGELOG.md

### Bug Fixes

1. Add a test that reproduces the bug
2. Fix the bug
3. Ensure all tests pass
4. Reference the issue in your commit

### Performance Improvements

1. Benchmark before and after
2. Document the improvement in the PR
3. Ensure no regression in functionality
4. Consider impact on binary size

## Pull Request Process

1. **Title**: Use conventional commits format (e.g., `feat:`, `fix:`, `docs:`)
2. **Description**: Explain what and why, not how
3. **Tests**: All tests must pass
4. **Documentation**: Update if needed
5. **Sign-off**: Sign your commits (`git commit -s`)

## Extension Development

See the [Extension SDK documentation](../extension-host/sdk/README.md) for:
- API reference
- Example extensions
- Publishing guidelines

## Debugging Tips

### Rust
```bash
RUST_LOG=debug cargo run -- record
RUST_BACKTRACE=1 cargo test
```

### Swift
Use Xcode for debugging:
```bash
cd apple_capture
swift package generate-xcodeproj
open *.xcodeproj
```

### Node.js
```bash
NODE_ENV=development node --inspect extension-host/dist/index.js
```

## Release Process

1. Update version in all `Cargo.toml` and `package.json` files
2. Update CHANGELOG.md
3. Create a tagged release
4. CI will build and upload artifacts

## Getting Help

- Check existing issues and discussions
- Join our Discord server (if applicable)
- Ask questions in issues with the "question" label

## Code of Conduct

- Be respectful and inclusive
- Focus on constructive criticism
- Help others learn and grow
- Report unacceptable behavior to maintainers

Thank you for contributing to TFT Recorder!
</file>

<file path="extension-host/sdk/index.d.ts">
// ABOUTME: Public API type definitions for extension authors
// ABOUTME: Provides TypeScript support for developing TFT recorder extensions

declare module '@tft-recorder/sdk' {
    export interface ExtensionContext {
        /**
         * Access to the recorder API
         */
        recorder: RecorderAPI;
        
        /**
         * Path where the extension is installed
         */
        extensionPath: string;
        
        /**
         * Global state storage
         */
        globalState: GlobalState;
        
        /**
         * Array to track disposables
         */
        subscriptions: Disposable[];
    }
    
    export interface RecorderAPI {
        /**
         * Start recording with specified options
         */
        startRecording(options?: RecordingOptions): Promise<boolean>;
        
        /**
         * Stop the current recording
         */
        stopRecording(): Promise<string | undefined>;
        
        /**
         * Get current recording status
         */
        getStatus(): Promise<RecordingStatus>;
        
        /**
         * Subscribe to recording events
         */
        onDidChangeRecordingState(callback: (event: RecordingStateEvent) => void): Disposable;
        
        /**
         * Subscribe to frame events during recording
         */
        onDidCaptureFrame(callback: (event: FrameEvent) => void): Disposable;
    }
    
    export interface RecordingOptions {
        windowTitle?: string;
        width?: number;
        height?: number;
        bitrate?: number;
        outputPath?: string;
    }
    
    export interface RecordingStatus {
        isRecording: boolean;
        currentRecordingId?: string;
        duration?: number;
        frameCount?: number;
        fileSize?: number;
    }
    
    export interface RecordingStateEvent {
        type: 'started' | 'stopped' | 'paused' | 'resumed';
        recordingId: string;
        timestamp: number;
    }
    
    export interface FrameEvent {
        recordingId: string;
        frameNumber: number;
        timestamp: number;
        pts: number;
    }
    
    export interface GlobalState {
        get<T>(key: string): T | undefined;
        set<T>(key: string, value: T): void;
        delete(key: string): void;
        keys(): string[];
    }
    
    export interface Disposable {
        dispose(): void;
    }
    
    /**
     * Commands API for registering extension commands
     */
    export namespace commands {
        export function registerCommand(
            command: string,
            callback: (...args: any[]) => any
        ): Disposable;
        
        export function executeCommand(command: string, ...args: any[]): Promise<any>;
        
        export function getCommands(): Promise<string[]>;
    }
    
    /**
     * Window API for UI interactions
     */
    export namespace window {
        export function showInformationMessage(message: string): void;
        export function showWarningMessage(message: string): void;
        export function showErrorMessage(message: string): void;
        
        export function showInputBox(options?: InputBoxOptions): Promise<string | undefined>;
        
        export function showQuickPick<T extends QuickPickItem>(
            items: T[],
            options?: QuickPickOptions
        ): Promise<T | undefined>;
    }
    
    export interface InputBoxOptions {
        prompt?: string;
        placeHolder?: string;
        value?: string;
        password?: boolean;
        validateInput?(value: string): string | null;
    }
    
    export interface QuickPickOptions {
        placeHolder?: string;
        canPickMany?: boolean;
        matchOnDescription?: boolean;
        matchOnDetail?: boolean;
    }
    
    export interface QuickPickItem {
        label: string;
        description?: string;
        detail?: string;
        picked?: boolean;
    }
    
    /**
     * Workspace API for file system operations
     */
    export namespace workspace {
        export function readFile(path: string): Promise<Buffer>;
        export function writeFile(path: string, content: Buffer | string): Promise<void>;
        export function deleteFile(path: string): Promise<void>;
        export function createDirectory(path: string): Promise<void>;
        export function listFiles(path: string): Promise<string[]>;
        
        export function getConfiguration(section?: string): Configuration;
    }
    
    export interface Configuration {
        get<T>(key: string): T | undefined;
        get<T>(key: string, defaultValue: T): T;
        has(key: string): boolean;
        update(key: string, value: any): Promise<void>;
    }
}
</file>

<file path="extension-host/src/index.ts">
#!/usr/bin/env node
// ABOUTME: Extension host entry point that manages plugin lifecycle and IPC
// ABOUTME: Provides VS Code-style extensibility for the TFT recorder

import { ExtensionLoader } from './loader';
import { RecorderIPC } from './ipc';
import { ExtensionContext } from './types';
import * as path from 'path';
import * as os from 'os';

async function main() {
    console.log('TFT Recorder Extension Host starting...');
    
    // Parse command line arguments
    const args = process.argv.slice(2);
    const portIndex = args.indexOf('--port');
    const port = portIndex !== -1 ? parseInt(args[portIndex + 1]) : 0;
    
    // Initialize IPC connection
    const recorder = new RecorderIPC(port);
    await recorder.connect();
    
    // Create extension context
    const context: ExtensionContext = {
        recorder,
        extensionPath: path.join(os.homedir(), '.tft-recorder', 'extensions'),
        globalState: new Map(),
        subscriptions: [],
    };
    
    // Load extensions
    const loader = new ExtensionLoader();
    const extensions = await loader.loadExtensions(context);
    
    console.log(`Loaded ${extensions.length} extensions`);
    
    // Handle shutdown
    process.on('SIGINT', async () => {
        console.log('Shutting down extension host...');
        
        // Deactivate extensions
        for (const ext of extensions) {
            if (ext.deactivate) {
                try {
                    await ext.deactivate();
                } catch (err) {
                    console.error(`Error deactivating extension ${ext.name}:`, err);
                }
            }
        }
        
        // Clean up subscriptions
        for (const disposable of context.subscriptions) {
            disposable.dispose();
        }
        
        await recorder.disconnect();
        process.exit(0);
    });
    
    // Keep process alive
    setInterval(() => {}, 1000);
}

main().catch(err => {
    console.error('Extension host failed:', err);
    process.exit(1);
});
</file>

<file path="extension-host/src/ipc.ts">
// ABOUTME: gRPC client for communicating with the recorder daemon
// ABOUTME: Handles recording control and event streaming over Unix sockets

import * as grpc from '@grpc/grpc-js';
import * as protoLoader from '@grpc/proto-loader';
import { EventEmitter } from 'events';
import * as path from 'path';

interface RecorderService {
    StartRecording(request: StartRecordingRequest): Promise<StartRecordingResponse>;
    StopRecording(request: StopRecordingRequest): Promise<StopRecordingResponse>;
    GetStatus(request: GetStatusRequest): Promise<GetStatusResponse>;
    StreamEvents(request: StreamEventsRequest): grpc.ClientReadableStream<RecordingEvent>;
}

interface StartRecordingRequest {
    windowTitle: string;
    width: number;
    height: number;
    bitrate: number;
    outputPath: string;
}

interface StartRecordingResponse {
    success: boolean;
    error?: string;
}

interface StopRecordingRequest {
    recordingId: string;
}

interface StopRecordingResponse {
    success: boolean;
    filePath?: string;
    error?: string;
}

interface GetStatusRequest {}

interface GetStatusResponse {
    isRecording: boolean;
    currentRecordingId?: string;
    duration?: number;
}

interface StreamEventsRequest {}

interface RecordingEvent {
    type: 'started' | 'stopped' | 'error' | 'frame';
    recordingId?: string;
    timestamp: number;
    data?: any;
}

export class RecorderIPC extends EventEmitter {
    private client?: any; // gRPC client
    private eventStream?: grpc.ClientReadableStream<RecordingEvent>;
    private socketPath: string;
    
    constructor(port: number = 0) {
        super();
        this.socketPath = port === 0 
            ? '/tmp/tft-recorder.sock' 
            : `localhost:${port}`;
    }
    
    async connect(): Promise<void> {
        // In a real implementation, we'd load the proto file
        // For now, we'll create a mock connection
        console.log(`Connecting to recorder at ${this.socketPath}`);
        
        // Simulate connection
        this.client = {
            StartRecording: async (req: StartRecordingRequest) => ({ success: true }),
            StopRecording: async (req: StopRecordingRequest) => ({ success: true }),
            GetStatus: async (req: GetStatusRequest) => ({ isRecording: false }),
        };
        
        this.emit('connected');
    }
    
    async disconnect(): Promise<void> {
        if (this.eventStream) {
            this.eventStream.cancel();
        }
        this.client = undefined;
        this.emit('disconnected');
    }
    
    async startRecording(options: {
        windowTitle?: string;
        width?: number;
        height?: number;
        bitrate?: number;
        outputPath?: string;
    }): Promise<boolean> {
        if (!this.client) {
            throw new Error('Not connected to recorder');
        }
        
        const request: StartRecordingRequest = {
            windowTitle: options.windowTitle || 'Teamfight Tactics',
            width: options.width || 1280,
            height: options.height || 720,
            bitrate: options.bitrate || 4000000,
            outputPath: options.outputPath || 'recording.mp4',
        };
        
        const response = await this.client.StartRecording(request);
        return response.success;
    }
    
    async stopRecording(): Promise<string | undefined> {
        if (!this.client) {
            throw new Error('Not connected to recorder');
        }
        
        const status = await this.getStatus();
        if (!status.isRecording || !status.currentRecordingId) {
            throw new Error('No active recording');
        }
        
        const response = await this.client.StopRecording({
            recordingId: status.currentRecordingId,
        });
        
        return response.filePath;
    }
    
    async getStatus(): Promise<GetStatusResponse> {
        if (!this.client) {
            throw new Error('Not connected to recorder');
        }
        
        return await this.client.GetStatus({});
    }
    
    subscribeToEvents(callback: (event: RecordingEvent) => void): void {
        this.on('recording-event', callback);
        
        // In a real implementation, we'd start the event stream here
        // For now, we'll simulate some events
        setTimeout(() => {
            this.emit('recording-event', {
                type: 'started',
                recordingId: 'test-123',
                timestamp: Date.now(),
            });
        }, 1000);
    }
}
</file>

<file path="extension-host/src/loader.ts">
// ABOUTME: Extension loader that discovers and activates plugins
// ABOUTME: Implements VS Code-style extension discovery and lifecycle management

import * as path from 'path';
import * as fs from 'fs/promises';
import { glob } from 'glob';
import { ExtensionContext, Extension, ExtensionManifest } from './types';

export class ExtensionLoader {
    async loadExtensions(context: ExtensionContext): Promise<Extension[]> {
        const extensions: Extension[] = [];
        
        // Ensure extensions directory exists
        try {
            await fs.mkdir(context.extensionPath, { recursive: true });
        } catch (err) {
            console.error('Failed to create extensions directory:', err);
        }
        
        // Find all extension directories
        const pattern = path.join(context.extensionPath, '*/package.json');
        const manifestPaths = await glob(pattern);
        
        for (const manifestPath of manifestPaths) {
            try {
                const extension = await this.loadExtension(manifestPath, context);
                if (extension) {
                    extensions.push(extension);
                }
            } catch (err) {
                console.error(`Failed to load extension from ${manifestPath}:`, err);
            }
        }
        
        return extensions;
    }
    
    private async loadExtension(
        manifestPath: string,
        context: ExtensionContext
    ): Promise<Extension | null> {
        // Read manifest
        const manifestData = await fs.readFile(manifestPath, 'utf-8');
        const manifest: ExtensionManifest = JSON.parse(manifestData);
        
        // Validate manifest
        if (!manifest.name || !manifest.main) {
            console.error(`Invalid manifest at ${manifestPath}`);
            return null;
        }
        
        // Load extension module
        const extensionDir = path.dirname(manifestPath);
        const mainPath = path.join(extensionDir, manifest.main);
        
        try {
            const module = require(mainPath);
            
            // Create extension object
            const extension: Extension = {
                name: manifest.name,
                version: manifest.version || '0.0.0',
                manifest,
                exports: module,
            };
            
            // Check activation events
            if (this.shouldActivate(manifest, context)) {
                // Activate extension
                if (typeof module.activate === 'function') {
                    console.log(`Activating extension: ${manifest.name}`);
                    const api = await module.activate(context);
                    extension.exports = api || module;
                }
                
                // Store deactivate function if present
                if (typeof module.deactivate === 'function') {
                    extension.deactivate = module.deactivate;
                }
            }
            
            return extension;
        } catch (err) {
            console.error(`Failed to load extension module ${mainPath}:`, err);
            return null;
        }
    }
    
    private shouldActivate(manifest: ExtensionManifest, context: ExtensionContext): boolean {
        // Always activate if no activation events specified
        if (!manifest.activationEvents || manifest.activationEvents.length === 0) {
            return true;
        }
        
        // Check activation events
        for (const event of manifest.activationEvents) {
            if (event === '*' || event === 'onStartup') {
                return true;
            }
            
            // TODO: Implement other activation events like onCommand, onRecordingStart, etc.
        }
        
        return false;
    }
}
</file>

<file path="extension-host/src/types.ts">
// ABOUTME: Type definitions for the extension host and plugin API
// ABOUTME: Defines the contract between the host and extensions

import { RecorderIPC } from './ipc';

export interface ExtensionContext {
    recorder: RecorderIPC;
    extensionPath: string;
    globalState: Map<string, any>;
    subscriptions: Disposable[];
}

export interface Disposable {
    dispose(): void;
}

export interface Extension {
    name: string;
    version: string;
    manifest: ExtensionManifest;
    exports: any;
    deactivate?: () => void | Promise<void>;
}

export interface ExtensionManifest {
    name: string;
    version?: string;
    displayName?: string;
    description?: string;
    main: string;
    activationEvents?: string[];
    contributes?: ExtensionContributions;
    engines?: {
        recorder?: string;
    };
    dependencies?: Record<string, string>;
}

export interface ExtensionContributions {
    commands?: Command[];
    configuration?: ConfigurationContribution;
    keybindings?: Keybinding[];
}

export interface Command {
    command: string;
    title: string;
    category?: string;
    icon?: string;
}

export interface ConfigurationContribution {
    title: string;
    properties: Record<string, ConfigurationProperty>;
}

export interface ConfigurationProperty {
    type: 'string' | 'number' | 'boolean' | 'array' | 'object';
    default?: any;
    description?: string;
    enum?: any[];
    minimum?: number;
    maximum?: number;
}

export interface Keybinding {
    command: string;
    key: string;
    when?: string;
    mac?: string;
    win?: string;
    linux?: string;
}
</file>

<file path="extension-host/package.json">
{
  "name": "@tft-recorder/extension-host",
  "version": "0.1.0",
  "description": "Extension host for TFT recorder plugins",
  "main": "dist/index.js",
  "scripts": {
    "build": "tsc",
    "watch": "tsc -w",
    "test": "jest"
  },
  "dependencies": {
    "@grpc/grpc-js": "^1.11.0",
    "@grpc/proto-loader": "^0.7.0",
    "glob": "^10.0.0"
  },
  "devDependencies": {
    "@types/node": "^18.0.0",
    "@types/glob": "^8.0.0",
    "typescript": "^5.0.0",
    "jest": "^29.0.0",
    "@types/jest": "^29.0.0"
  }
}
</file>

<file path="extension-host/tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "commonjs",
    "lib": ["ES2022"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "moduleResolution": "node"
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist", "**/*.test.ts"]
}
</file>

<file path="mac_app/entitlements.plist">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <!-- App Sandbox - optional but recommended for App Store -->
    <key>com.apple.security.app-sandbox</key>
    <false/>
    
    <!-- Allow automation for window detection -->
    <key>com.apple.security.automation.apple-events</key>
    <true/>
    
    <!-- File access for saving recordings -->
    <key>com.apple.security.files.user-selected.read-write</key>
    <true/>
    
    <!-- For future updates -->
    <key>com.apple.security.network.client</key>
    <true/>
    
    <!-- Device access is handled by TCC, not entitlements -->
</dict>
</plist>
</file>

<file path="recorder_cli/src/gui.rs">
// ABOUTME: GUI module for TFT Recorder using egui/eframe
// ABOUTME: Provides a minimalist interface for recording and managing recordings

use eframe::{egui, NativeOptions};
use recorder_core::Recorder;
use std::fs;
use std::path::PathBuf;
use std::sync::{Arc, Mutex};

const RECORDINGS_DIR: &str = "~/Movies/TFT Recorder";

pub fn launch() -> anyhow::Result<()> {
    // Create the recordings directory if it doesn't exist
    let recordings_path = expand_home(RECORDINGS_DIR);
    fs::create_dir_all(&recordings_path)?;

    let options = NativeOptions {
        viewport: egui::ViewportBuilder::default()
            .with_inner_size([800.0, 600.0]),
        ..Default::default()
    };
    
    eframe::run_native(
        "TFT Recorder",
        options,
        Box::new(|_cc| Box::<RecorderApp>::default()),
    )
    .map_err(|e| anyhow::anyhow!("eframe failed: {e}"))
}

#[derive(Default)]
struct RecorderApp {
    recorder: Arc<Mutex<Recorder>>,
    is_recording: bool,
    error_message: Option<String>,
}

impl eframe::App for RecorderApp {
    fn update(&mut self, ctx: &egui::Context, _frame: &mut eframe::Frame) {
        // Left panel with recordings list
        egui::SidePanel::left("recordings_panel")
            .default_width(250.0)
            .show(ctx, |ui| {
                ui.heading("Recordings");
                ui.separator();
                
                egui::ScrollArea::vertical().show(ui, |ui| {
                    let recordings = list_recordings();
                    
                    if recordings.is_empty() {
                        ui.label("No recordings yet");
                    } else {
                        for recording in recordings {
                            let file_name = recording
                                .file_name()
                                .and_then(|n| n.to_str())
                                .unwrap_or("Unknown");
                            
                            if ui.button(file_name).clicked() {
                                // Reveal in Finder
                                let _ = std::process::Command::new("open")
                                    .arg("-R")
                                    .arg(&recording)
                                    .spawn();
                            }
                        }
                    }
                });
            });

        // Central panel with recording controls
        egui::CentralPanel::default().show(ctx, |ui| {
            ui.vertical_centered(|ui| {
                ui.add_space(50.0);
                
                if self.is_recording {
                    ui.heading("Recording in progress...");
                    ui.add_space(20.0);
                    
                    if ui.button("⏹ Stop Recording").clicked() {
                        if let Ok(mut recorder) = self.recorder.lock() {
                            recorder.stop();
                            self.is_recording = false;
                        }
                    }
                } else {
                    ui.heading("Ready to Record");
                    ui.add_space(20.0);
                    
                    if ui.button("⏺ Start New Recording").clicked() {
                        self.start_recording();
                    }
                    
                    ui.add_space(10.0);
                    ui.label("Recording will capture your entire screen");
                    ui.label("Files are saved to ~/Movies/TFT Recorder");
                }
                
                // Show error message if any
                if let Some(error) = &self.error_message {
                    ui.add_space(20.0);
                    ui.colored_label(egui::Color32::RED, error);
                    
                    if ui.button("Dismiss").clicked() {
                        self.error_message = None;
                    }
                }
            });
        });
        
        // Request repaint if recording (to update UI state)
        if self.is_recording {
            ctx.request_repaint_after(std::time::Duration::from_millis(100));
        }
    }
}

impl RecorderApp {
    fn start_recording(&mut self) {
        let output_path = next_file_name();
        
        if let Ok(mut recorder) = self.recorder.lock() {
            // Try to record the desktop (entire screen)
            // We'll use "Desktop" as the window name, though this might need adjustment
            match recorder.start("Desktop", 1920, 1080, 6_000_000, &output_path) {
                Ok(_) => {
                    self.is_recording = true;
                    self.error_message = None;
                }
                Err(e) => {
                    self.error_message = Some(format!("Failed to start recording: {}", e));
                }
            }
        }
    }
}

// Helper functions

pub fn expand_home(path: &str) -> PathBuf {
    PathBuf::from(shellexpand::tilde(path).as_ref())
}

fn list_recordings() -> Vec<PathBuf> {
    let dir = expand_home(RECORDINGS_DIR);
    
    if let Ok(entries) = fs::read_dir(&dir) {
        let mut recordings: Vec<PathBuf> = entries
            .filter_map(|entry| {
                let entry = entry.ok()?;
                let path = entry.path();
                
                // Only include .mp4 files
                if path.extension()?.to_str()? == "mp4" {
                    Some(path)
                } else {
                    None
                }
            })
            .collect();
        
        // Sort by modification time (newest first)
        recordings.sort_by(|a, b| {
            let a_time = fs::metadata(a).and_then(|m| m.modified()).ok();
            let b_time = fs::metadata(b).and_then(|m| m.modified()).ok();
            b_time.cmp(&a_time)
        });
        
        recordings
    } else {
        Vec::new()
    }
}

pub fn next_file_name() -> String {
    let timestamp = chrono::Local::now().format("%Y-%m-%d-%H%M%S");
    let dir = expand_home(RECORDINGS_DIR);
    format!("{}/TFT-{}.mp4", dir.display(), timestamp)
}

// Re-export for use in main.rs
pub use self::next_file_name as get_default_output_path;
</file>

<file path="recorder_cli/src/lib.rs">
// ABOUTME: Library exports for recorder_cli to enable testing
// ABOUTME: Exposes the gui module for integration tests

pub mod gui;
</file>

<file path="recorder_cli/tests/bundle_build.rs">
// ABOUTME: Integration test to verify macOS app bundle can be generated
// ABOUTME: Ensures CI will catch any bundle configuration issues

#![cfg(target_os = "macos")]

#[test]
#[ignore] // Run with: cargo test -- --ignored
fn tft_recorder_app_builds() {
    use std::process::Command;
    
    // Check if cargo-bundle is installed
    let check = Command::new("cargo")
        .args(&["bundle", "--version"])
        .output()
        .expect("Failed to check cargo-bundle");
        
    if !check.status.success() {
        eprintln!("cargo-bundle not installed. Install with: cargo install cargo-bundle");
        panic!("cargo-bundle is required for this test");
    }
    
    // Try to build the bundle
    let status = Command::new("cargo")
        .args(&["bundle", "--bin", "recorder", "--release"])
        .status()
        .expect("Failed to spawn cargo-bundle");
        
    assert!(
        status.success(),
        "cargo bundle failed; see stdout/stderr for details"
    );

    // Verify the app bundle was created
    let app = std::path::Path::new("target/release/bundle/osx/TFT Recorder.app");
    assert!(app.exists(), "Bundle path missing: {:?}", app);
    
    // Check that the main executable exists
    let exe = app.join("Contents/MacOS/recorder");
    assert!(exe.exists(), "Bundle executable missing: {:?}", exe);
    
    // Check that Info.plist was created
    let info_plist = app.join("Contents/Info.plist");
    assert!(info_plist.exists(), "Info.plist missing: {:?}", info_plist);
}
</file>

<file path="recorder_cli/tests/bundle_dylib.rs">
// ABOUTME: End-to-end test to verify Swift dylib is properly included in app bundle
// ABOUTME: Catches dyld issues that would cause silent app exits

#![cfg(target_os = "macos")]

#[test]
#[ignore] // Run with: cargo test -- --ignored
fn dylib_in_bundle() {
    use std::process::Command;
    use std::path::Path;

    // Build via the helper script
    // Find the workspace root by looking for Cargo.toml
    let workspace_root = std::env::current_dir()
        .expect("Failed to get current dir")
        .ancestors()
        .find(|p| p.join("Cargo.toml").exists() && p.join("scripts/package_app.sh").exists())
        .expect("Could not find workspace root")
        .to_path_buf();
    
    let status = Command::new("bash")
        .arg("scripts/package_app.sh")
        .current_dir(&workspace_root)
        .status()
        .expect("Failed to run package_app.sh");
    
    assert!(status.success(), "package_app.sh failed");

    let app = workspace_root.join("target/release/bundle/osx/TFT Recorder.app");
    assert!(app.exists(), "App bundle not found at {:?}", app);
    
    let dylib = app.join("Contents/Frameworks/libAppleCapture.dylib");
    assert!(dylib.exists(), "Swift dylib missing in bundle at {:?}", dylib);
    
    // Also verify the icon is present
    let icon = app.join("Contents/Resources/tft.icns");
    assert!(icon.exists(), "Icon missing in bundle at {:?}", icon);
    
    // Verify the executable exists
    let exe = app.join("Contents/MacOS/recorder");
    assert!(exe.exists(), "Executable missing in bundle at {:?}", exe);
}
</file>

<file path="recorder_cli/tests/gui_test.rs">
// ABOUTME: Basic test to ensure GUI module compiles and initializes properly
// ABOUTME: Does not actually launch the GUI window to avoid blocking tests

#[test]
fn gui_module_compiles() {
    // Just ensure the module is accessible
    use recorder_cli::gui;
    
    // Verify the get_default_output_path function works
    let path = gui::get_default_output_path();
    assert!(path.contains("TFT-"));
    assert!(path.contains(".mp4"));
    assert!(path.contains("Movies/TFT Recorder"));
}

#[test]
fn gui_expand_home_works() {
    use recorder_cli::gui::expand_home;
    
    let expanded = expand_home("~/test");
    assert!(!expanded.to_string_lossy().starts_with("~"));
    
    let no_tilde = expand_home("/absolute/path");
    assert_eq!(no_tilde.to_string_lossy(), "/absolute/path");
}
</file>

<file path="recorder_cli/tests/rpath_check.rs">
// ABOUTME: Test to verify the binary has correct rpath settings for dylib loading
// ABOUTME: Prevents shipping binaries that can't find their dynamic libraries

#[test]
#[cfg(target_os = "macos")]
fn binary_has_frameworks_rpath() {
    use std::process::Command;
    
    // First, ensure the binary exists
    let binary_path = "target/release/recorder";
    if !std::path::Path::new(binary_path).exists() {
        eprintln!("Binary not found at {}, building it first...", binary_path);
        
        // Build the release binary
        let build_status = Command::new("cargo")
            .args(&["build", "--bin", "recorder", "--release"])
            .status()
            .expect("Failed to run cargo build");
            
        assert!(build_status.success(), "Failed to build release binary");
    }
    
    // Run otool to check for rpath entries
    let output = Command::new("otool")
        .args(&["-l", binary_path])
        .output()
        .expect("Failed to run otool");
    
    let text = String::from_utf8_lossy(&output.stdout);
    
    // Check for the required rpath
    assert!(
        text.contains("@executable_path/../Frameworks"),
        "Binary missing @executable_path/../Frameworks rpath. Output:\n{}",
        text
    );
}

#[test]
#[cfg(target_os = "macos")]
#[ignore] // Run with: cargo test -- --ignored
fn bundle_binary_has_correct_dylib_references() {
    use std::process::Command;
    use std::path::Path;
    
    // Run packaging script first
    let workspace_root = std::env::current_dir()
        .expect("Failed to get current dir")
        .ancestors()
        .find(|p| p.join("Cargo.toml").exists() && p.join("scripts/package_app.sh").exists())
        .expect("Could not find workspace root")
        .to_path_buf();
    
    let status = Command::new("bash")
        .arg("scripts/package_app.sh")
        .current_dir(&workspace_root)
        .status()
        .expect("Failed to run package_app.sh");
    
    assert!(status.success(), "package_app.sh failed");
    
    let bundle_binary = workspace_root.join("target/release/bundle/osx/TFT Recorder.app/Contents/MacOS/recorder");
    assert!(bundle_binary.exists(), "Bundle binary not found at {:?}", bundle_binary);
    
    // Check that the binary references libAppleCapture.dylib via @rpath
    let output = Command::new("otool")
        .args(&["-L", bundle_binary.to_str().unwrap()])
        .output()
        .expect("Failed to run otool -L");
    
    let text = String::from_utf8_lossy(&output.stdout);
    
    assert!(
        text.contains("@rpath/libAppleCapture.dylib"),
        "Binary not referencing libAppleCapture.dylib via @rpath. Output:\n{}",
        text
    );
}
</file>

<file path="recorder_cli/build.rs">
// ABOUTME: Build script for recorder_cli to set proper rpath for dylib loading
// ABOUTME: Ensures the binary can find libAppleCapture.dylib both in bundle and development

#[cfg(target_os = "macos")]
fn main() {
    // Add rpaths that work both inside app bundles and in development
    println!("cargo:rustc-link-arg=-Wl,-rpath,@executable_path/../Frameworks");
    println!("cargo:rustc-link-arg=-Wl,-rpath,@loader_path/../Frameworks");
}

#[cfg(not(target_os = "macos"))]
fn main() {}
</file>

<file path="recorder_core/benches/capture_bench.rs">
// ABOUTME: Performance benchmarks for recorder initialization and operations
// ABOUTME: Ensures startup time stays under 50ms for responsive user experience

use criterion::{black_box, criterion_group, criterion_main, Criterion};
use recorder_core::Recorder;

fn bench_recorder_creation(c: &mut Criterion) {
    c.bench_function("recorder_new", |b| {
        b.iter(|| {
            let recorder = Recorder::new();
            black_box(recorder);
        });
    });
}

fn bench_recorder_lifecycle(c: &mut Criterion) {
    c.bench_function("recorder_start_stop", |b| {
        b.iter(|| {
            let mut recorder = Recorder::new();
            
            // Attempt to start (will fail without valid window, but measures overhead)
            let _ = recorder.start(
                "Benchmark Window",
                1280,
                720,
                4000000,
                "/tmp/bench.mp4"
            );
            
            recorder.stop();
            black_box(recorder);
        });
    });
}

fn bench_is_recording_check(c: &mut Criterion) {
    let recorder = Recorder::new();
    
    c.bench_function("is_recording", |b| {
        b.iter(|| {
            black_box(recorder.is_recording());
        });
    });
}

criterion_group!(benches, bench_recorder_creation, bench_recorder_lifecycle, bench_is_recording_check);
criterion_main!(benches);
</file>

<file path="recorder_core/src/tests/ffi_integration.rs">
// ABOUTME: Integration tests for Swift-Rust FFI bridge
// ABOUTME: Tests actual screen recording functionality on macOS

#[cfg(target_os = "macos")]
#[cfg(test)]
mod tests {
    use crate::Recorder;
    use std::path::Path;

    #[test]
    fn test_start_stop_finder() {
        // Finder is always running on macOS
        let mut rec = Recorder::new();
        let output_path = "/tmp/finder_test.mp4";
        
        // Remove any existing file
        let _ = std::fs::remove_file(output_path);
        
        // Try to record Finder window
        let res = rec.start("Finder", 640, 360, 1_000_000, output_path);
        
        // This might fail if:
        // 1. No screen recording permission
        // 2. No Finder window visible
        // 3. Running in CI environment
        if res.is_ok() {
            assert!(rec.is_recording(), "Should be recording after successful start");
            
            // Record for a short time
            std::thread::sleep(std::time::Duration::from_millis(500));
            
            rec.stop();
            assert!(!rec.is_recording(), "Should not be recording after stop");
            
            // Check if file was created
            assert!(Path::new(output_path).exists(), "Output file should exist");
            
            // Clean up
            let _ = std::fs::remove_file(output_path);
        } else {
            // If start failed, just ensure we're in a consistent state
            assert!(!rec.is_recording(), "Should not be recording after failed start");
            println!("Note: Recording test skipped (no permission or window)");
        }
    }

    #[test]
    fn test_invalid_window_fails() {
        let mut rec = Recorder::new();
        
        // This should always fail
        let res = rec.start(
            "NonExistentWindow_TestOnly_12345",
            640,
            360,
            1_000_000,
            "/tmp/should_not_exist.mp4"
        );
        
        assert!(res.is_err(), "Should fail with non-existent window");
        assert!(!rec.is_recording(), "Should not be recording after failed start");
    }

    #[test]
    fn test_concurrent_recording_fails() {
        let mut rec = Recorder::new();
        
        // First attempt (might succeed or fail depending on environment)
        let first_result = rec.start("Finder", 640, 360, 1_000_000, "/tmp/test1.mp4");
        
        if first_result.is_ok() {
            // If first succeeded, second should fail
            let second_result = rec.start("Finder", 640, 360, 1_000_000, "/tmp/test2.mp4");
            assert!(second_result.is_err(), "Second recording should fail");
            assert!(rec.is_recording(), "Should still be recording from first start");
            
            // Clean up
            rec.stop();
            let _ = std::fs::remove_file("/tmp/test1.mp4");
        }
    }
}
</file>

<file path="recorder_core/src/tests/ffi_smoke.rs">
// ABOUTME: Basic smoke tests for FFI bridge functionality
// ABOUTME: Ensures Rust-Swift integration symbols are available

#[cfg(test)]
mod tests {
    use crate::Recorder;

    #[test]
    fn test_recorder_new() {
        let recorder = Recorder::new();
        assert!(!recorder.is_recording());
    }

    #[test]
    fn test_recorder_lifecycle() {
        let mut recorder = Recorder::new();
        
        // Should not be recording initially
        assert!(!recorder.is_recording());
        
        // Stop should be safe even when not recording
        recorder.stop();
        assert!(!recorder.is_recording());
    }

    #[test]
    #[cfg(target_os = "macos")]
    fn test_recorder_start_invalid_window() {
        let mut recorder = Recorder::new();
        
        // Starting with non-existent window should fail
        let result = recorder.start(
            "NonExistentWindow12345",
            1280,
            720,
            4000000,
            "/tmp/test_invalid.mp4"
        );
        
        assert!(result.is_err());
        assert!(!recorder.is_recording());
    }

    #[test]
    fn test_concurrent_recorders() {
        let recorder1 = Recorder::new();
        let recorder2 = Recorder::new();
        
        // Both should be independent
        assert!(!recorder1.is_recording());
        assert!(!recorder2.is_recording());
    }
}
</file>

<file path="resources/tft.icns.placeholder">
This is a placeholder for the TFT Recorder icon.
To create a proper .icns file:
1. Create a 1024x1024 PNG image
2. Use iconutil or an app like Icon Set Creator to convert to .icns
3. Replace this file with the actual tft.icns
</file>

<file path=".gitignore">
# Rust
target/
Cargo.lock
**/*.rs.bk
*.pdb

# Swift
.build/
.swiftpm/
*.xcodeproj
xcuserdata/
DerivedData/
.DS_Store

# Node.js
node_modules/
dist/
*.log
npm-debug.log*
.npm
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Test outputs
*.mp4
*.mov
/tmp/

# Extension development
.tft-recorder/
</file>

<file path="Cargo.toml">
[workspace]
members = ["recorder_core", "recorder_cli"]
resolver = "2"

[workspace.package]
version = "0.1.0"
edition = "2021"
authors = ["TFT Recorder Contributors"]
license = "MIT"
repository = "https://github.com/yourusername/tft-recorder"

[workspace.dependencies]
anyhow = "1.0"
tokio = { version = "1.39", features = ["full"] }
tonic = "0.12"
clap = { version = "4.5", features = ["derive"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
cxx = "1.0"

[profile.release]
lto = true
codegen-units = 1
strip = true
opt-level = "z"
</file>

<file path="package.json">
{
  "name": "tft-recorder",
  "version": "0.1.0",
  "description": "Mac-first screen recorder for Team Fight Tactics with VS Code-style extensibility",
  "private": true,
  "scripts": {
    "build": "tsc",
    "test": "jest",
    "lint": "eslint src --ext .ts",
    "typecheck": "tsc --noEmit"
  },
  "workspaces": [
    "extension-host"
  ],
  "devDependencies": {
    "@types/node": "^18.0.0",
    "@typescript-eslint/eslint-plugin": "^5.0.0",
    "@typescript-eslint/parser": "^5.0.0",
    "eslint": "^8.0.0",
    "jest": "^29.0.0",
    "typescript": "^5.0.0"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/yourusername/tft-recorder.git"
  },
  "keywords": [
    "screen-recorder",
    "tft",
    "teamfight-tactics",
    "macos",
    "rust",
    "swift"
  ],
  "author": "",
  "license": "MIT",
  "engines": {
    "node": ">=18.0.0"
  }
}
</file>

<file path="README.md">
# TFT Recorder

Ultra-light screen recorder for Team Fight Tactics (TFT) with VS Code-style extensibility.

## Features

- **Ultra-light binary**: ≤ 40 MB single-file .app bundle
- **Hardware H.264 encoding**: 5-10× less CPU usage vs software encoding
- **Plugin ecosystem**: VS Code-style extension support
- **Mac-first design**: Built specifically for macOS using native APIs

## Quick Start

```bash
# Record TFT at 720p
recorder record

# Record with custom settings
recorder record --width 1920 --height 1080 --bitrate 8000000 --out gameplay.mp4

# Stop recording with Ctrl+C
```

## Installation

### Prerequisites

- macOS 12.0 or later
- Rust 1.79+
- Swift 5.10+
- Node.js 18+

### Building from source

```bash
# Clone the repository
git clone https://github.com/yourusername/tft-recorder.git
cd tft-recorder

# Build Swift package
cd apple_capture
swift build -c release
cd ..

# Build Rust binary
cargo build --release

# The binary will be at ./target/release/recorder
```

## Architecture

The recorder consists of three main components:

1. **Swift Capture Library** (`apple_capture/`): Handles screen capture using AVFoundation and hardware encoding via VideoToolbox
2. **Rust Core & CLI** (`recorder_core/` & `recorder_cli/`): Provides the main binary and FFI bridge to Swift
3. **Node.js Extension Host** (`extension-host/`): Manages plugins with VS Code-style extensibility

## Extension Development

Extensions follow the VS Code extension model. Create a `package.json` with:

```json
{
  "name": "my-extension",
  "version": "0.1.0",
  "main": "dist/index.js",
  "activationEvents": ["onRecordingStart"],
  "contributes": {
    "commands": [{
      "command": "myExtension.doSomething",
      "title": "Do Something Cool"
    }]
  }
}
```

Place extensions in `~/.tft-recorder/extensions/`.

## Performance

- Cold start: < 50ms
- CPU usage during 1080p/60fps capture: < 150%
- Memory usage: < 100MB
- File size: ~1MB/minute at 720p/4Mbps

## Contributing

See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for development guidelines.

## License

MIT License - see LICENSE file for details.
</file>

<file path="apple_capture/Sources/AppleCapture/CaptureSession.swift">
// ABOUTME: Main capture session manager using AVFoundation for screen recording
// ABOUTME: Handles window targeting, frame capture, and session lifecycle

import AVFoundation
import CoreGraphics
import VideoToolbox

public final class CaptureSession: NSObject {
    private let session = AVCaptureSession()
    private let queue = DispatchQueue(label: "apple_capture", qos: .userInitiated)
    private var encoder: Encoder?
    
    public override init() {
        super.init()
    }
    
    public func start(windowTitle: String,
                      width: Int,
                      height: Int,
                      bitrate: Int,
                      outputURL: URL,
                      onError: @escaping (Error) -> Void) {
        
        queue.async { [weak self] in
            guard let self = self else { return }
            do {
                try self.configure(windowTitle: windowTitle,
                                   width: width, 
                                   height: height, 
                                   bitrate: bitrate,
                                   outputURL: outputURL)
                self.session.startRunning()
            } catch {
                onError(error)
            }
        }
    }
    
    public func stop() {
        queue.async { [weak self] in
            self?.session.stopRunning()
            self?.encoder?.finalizeRecording()
        }
    }
    
    // MARK: - Private helpers
    private func configure(windowTitle: String,
                           width: Int, 
                           height: Int,
                           bitrate: Int,
                           outputURL: URL) throws {
        session.beginConfiguration()
        defer { session.commitConfiguration() }
        
        session.sessionPreset = .high
        
        // Find window by title
        let windowList = CGWindowListCopyWindowInfo([.optionAll], kCGNullWindowID) as? [[String: Any]] ?? []
        
        guard let windowInfo = windowList.first(where: { window in
            (window[kCGWindowName as String] as? String) == windowTitle
        }) else {
            throw CaptureError.windowNotFound
        }
        
        guard windowInfo[kCGWindowNumber as String] as? Int != nil else {
            throw CaptureError.invalidWindowNumber
        }
        
        // Get main display ID
        let displayID = CGMainDisplayID()
        
        // Create screen input
        guard let input = AVCaptureScreenInput(displayID: displayID) else {
            throw CaptureError.cannotCreateInput
        }
        
        // Configure input
        input.minFrameDuration = CMTime(value: 1, timescale: 60) // 60 fps max
        input.capturesCursor = true
        input.capturesMouseClicks = true
        
        // Calculate scale factor
        let displayWidth = CGDisplayPixelsWide(displayID)
        if displayWidth > 0 && width > 0 {
            input.scaleFactor = CGFloat(width) / CGFloat(displayWidth)
        }
        
        // Add input to session
        if session.canAddInput(input) {
            session.addInput(input)
        } else {
            throw CaptureError.cannotAddInput
        }
        
        // Create and configure encoder
        encoder = try Encoder(outputURL: outputURL,
                              width: width,
                              height: height,
                              bitrate: bitrate)
        
        try encoder?.attach(to: session)
    }
}

public enum CaptureError: LocalizedError {
    case windowNotFound
    case invalidWindowNumber
    case cannotCreateInput
    case cannotAddInput
    case encoderSetupFailed
    
    public var errorDescription: String? {
        switch self {
        case .windowNotFound:
            return "Window with specified title not found"
        case .invalidWindowNumber:
            return "Invalid window number"
        case .cannotCreateInput:
            return "Cannot create screen capture input"
        case .cannotAddInput:
            return "Cannot add input to capture session"
        case .encoderSetupFailed:
            return "Failed to setup video encoder"
        }
    }
}
</file>

<file path="apple_capture/Sources/AppleCapture/Encoder.swift">
// ABOUTME: Hardware H.264 encoder using AVAssetWriter and VideoToolbox
// ABOUTME: Handles real-time encoding with minimal CPU usage for TFT recording

import AVFoundation
import VideoToolbox
import CoreMedia

final class Encoder: NSObject {
    private let writer: AVAssetWriter
    private let input: AVAssetWriterInput
    private let adaptor: AVAssetWriterInputPixelBufferAdaptor
    private let queue = DispatchQueue(label: "encoder", qos: .userInitiated)
    private var isWriting = false
    
    init(outputURL: URL, width: Int, height: Int, bitrate: Int) throws {
        // Remove existing file if present
        try? FileManager.default.removeItem(at: outputURL)
        
        // Create writer
        writer = try AVAssetWriter(outputURL: outputURL, fileType: .mp4)
        
        // Configure H.264 settings
        let settings: [String: Any] = [
            AVVideoCodecKey: AVVideoCodecType.h264,
            AVVideoWidthKey: width,
            AVVideoHeightKey: height,
            AVVideoCompressionPropertiesKey: [
                AVVideoAverageBitRateKey: bitrate,
                AVVideoMaxKeyFrameIntervalKey: 60, // Keyframe every second at 60fps
                AVVideoProfileLevelKey: AVVideoProfileLevelH264HighAutoLevel,
                AVVideoH264EntropyModeKey: AVVideoH264EntropyModeCABAC
            ] as [String: Any]
        ]
        
        // Create input
        input = AVAssetWriterInput(mediaType: .video, outputSettings: settings)
        input.expectsMediaDataInRealTime = true
        
        // Create pixel buffer adaptor
        let sourcePixelBufferAttributes: [String: Any] = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA,
            kCVPixelBufferWidthKey as String: width,
            kCVPixelBufferHeightKey as String: height,
            kCVPixelBufferIOSurfacePropertiesKey as String: [:] // Enable IOSurface for better performance
        ]
        
        adaptor = AVAssetWriterInputPixelBufferAdaptor(
            assetWriterInput: input,
            sourcePixelBufferAttributes: sourcePixelBufferAttributes
        )
        
        // Add input to writer
        if writer.canAdd(input) {
            writer.add(input)
        } else {
            throw CaptureError.encoderSetupFailed
        }
        
        super.init()
    }
    
    func attach(to session: AVCaptureSession) throws {
        let output = AVCaptureVideoDataOutput()
        output.setSampleBufferDelegate(self, queue: queue)
        
        // Configure output
        output.videoSettings = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
        ]
        
        // Disable frame dropping for consistent recording
        output.alwaysDiscardsLateVideoFrames = false
        
        if session.canAddOutput(output) {
            session.addOutput(output)
        } else {
            throw CaptureError.encoderSetupFailed
        }
    }
    
    func finalizeRecording() {
        queue.async { [weak self] in
            guard let self = self, self.isWriting else { return }
            
            self.input.markAsFinished()
            self.writer.finishWriting {
                print("Recording finished: \(self.writer.status == .completed ? "Success" : "Failed")")
            }
        }
    }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate
extension Encoder: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput,
                       didOutput sampleBuffer: CMSampleBuffer,
                       from connection: AVCaptureConnection) {
        
        guard CMSampleBufferDataIsReady(sampleBuffer) else { return }
        
        let presentationTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
        
        // Start writing on first frame
        if !isWriting {
            guard writer.status == .unknown else { return }
            
            writer.startWriting()
            writer.startSession(atSourceTime: presentationTime)
            isWriting = true
        }
        
        // Write frame
        guard writer.status == .writing,
              input.isReadyForMoreMediaData,
              let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
            return
        }
        
        adaptor.append(imageBuffer, withPresentationTime: presentationTime)
    }
    
    func captureOutput(_ output: AVCaptureOutput,
                       didDrop sampleBuffer: CMSampleBuffer,
                       from connection: AVCaptureConnection) {
        print("Dropped frame at: \(CMSampleBufferGetPresentationTimeStamp(sampleBuffer).seconds)")
    }
}
</file>

<file path="apple_capture/Sources/AppleCaptureC/bridge.c">
// ABOUTME: Empty placeholder - actual implementation is in Swift FFIExports.swift
// ABOUTME: This file exists only to satisfy the C target requirement
</file>

<file path="apple_capture/Sources/AppleCaptureTests/CaptureSessionTests.swift">
// ABOUTME: Unit tests for the AppleCapture screen recording functionality
// ABOUTME: Tests basic capture session creation and short recordings

import XCTest
@testable import AppleCapture

final class CaptureSessionTests: XCTestCase {
    
    func testCaptureSessionCreation() {
        let session = CaptureSession()
        XCTAssertNotNil(session, "Should create capture session")
    }
    
    func testFiveSecondCapture() throws {
        // This test requires screen recording permission and a valid window
        // Skip in environments where this might not be available
        print("Note: This test requires screen recording permission and may fail without it")
        
        let expectation = self.expectation(description: "Capture completes or errors")
        let url = URL(fileURLWithPath: "/tmp/test_capture.mp4")
        
        // Clean up any existing file
        try? FileManager.default.removeItem(at: url)
        
        let capture = CaptureSession()
        var didError = false
        
        capture.start(windowTitle: "Finder", // Use Finder as it's always present
                      width: 640,
                      height: 360,
                      bitrate: 1_000_000,
                      outputURL: url) { error in
            // Don't fail the test, just note that capture couldn't start
            print("Capture error (expected in test environment): \(error.localizedDescription)")
            didError = true
            expectation.fulfill()
        }
        
        if !didError {
            // Record for 2 seconds if capture started
            DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                capture.stop()
                expectation.fulfill()
            }
        }
        
        wait(for: [expectation], timeout: 5)
        
        // Only check file if capture didn't error
        if !didError && FileManager.default.fileExists(atPath: url.path) {
            let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
            let fileSize = attributes[.size] as? Int64 ?? 0
            
            XCTAssertGreaterThan(fileSize, 1_000, "File should be at least 1KB")
            XCTAssertLessThan(fileSize, 10_000_000, "File should be less than 10MB")
            
            // Clean up
            try? FileManager.default.removeItem(at: url)
        }
    }
    
    func testInvalidWindowCapture() {
        let expectation = self.expectation(description: "Error callback triggered")
        let url = URL(fileURLWithPath: "/tmp/invalid_capture.mp4")
        let capture = CaptureSession()
        
        capture.start(windowTitle: "NonExistentWindow12345",
                      width: 640,
                      height: 360,
                      bitrate: 1_000_000,
                      outputURL: url) { error in
            XCTAssertNotNil(error, "Should receive error for invalid window")
            expectation.fulfill()
        }
        
        wait(for: [expectation], timeout: 5)
    }
    
    func testFrameRingBuffer() {
        let buffer = FrameRingBuffer(capacity: 10)
        
        // Create dummy pixel buffers
        var pixelBuffer: CVPixelBuffer?
        let attrs = [
            kCVPixelBufferCGImageCompatibilityKey: true,
            kCVPixelBufferCGBitmapContextCompatibilityKey: true
        ] as CFDictionary
        
        CVPixelBufferCreate(kCFAllocatorDefault, 100, 100,
                            kCVPixelFormatType_32BGRA, attrs, &pixelBuffer)
        
        guard let pb = pixelBuffer else {
            XCTFail("Failed to create pixel buffer")
            return
        }
        
        // Test appending
        for _ in 0..<15 {
            buffer.append(pb)
        }
        
        // Should only keep last 10 frames
        let frames = buffer.getFrames(last: 1.0)
        XCTAssertLessThanOrEqual(frames.count, 10, "Should not exceed buffer capacity")
        
        buffer.clear()
        let clearedFrames = buffer.getFrames(last: 1.0)
        XCTAssertEqual(clearedFrames.count, 0, "Buffer should be empty after clear")
    }
}
</file>

<file path="mac_app/Info.plist">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>CFBundleName</key>
    <string>TFT Recorder</string>
    <key>CFBundleDisplayName</key>
    <string>TFT Recorder</string>
    <key>CFBundleIdentifier</key>
    <string>com.tftreplay.recorder</string>
    <key>CFBundleVersion</key>
    <string>0.1.0</string>
    <key>CFBundleShortVersionString</key>
    <string>0.1.0</string>
    <key>CFBundlePackageType</key>
    <string>APPL</string>
    <key>CFBundleSignature</key>
    <string>????</string>
    <key>CFBundleExecutable</key>
    <string>recorder</string>
    <key>CFBundleIconFile</key>
    <string>tft.icns</string>
    <key>LSMinimumSystemVersion</key>
    <string>12.0</string>
    <key>LSApplicationCategoryType</key>
    <string>public.app-category.video</string>
    
    <!-- Privacy usage descriptions for TCC -->
    <key>NSCameraUsageDescription</key>
    <string>TFT Recorder needs screen recording permission to capture your gameplay.</string>
    <key>NSMicrophoneUsageDescription</key>
    <string>TFT Recorder can optionally record audio from your microphone for commentary.</string>
    
    <!-- High resolution support -->
    <key>NSHighResolutionCapable</key>
    <true/>
    
    <!-- Support for dark mode -->
    <key>NSRequiresAquaSystemAppearance</key>
    <false/>
</dict>
</plist>
</file>

<file path="recorder_core/src/lib.rs">
// ABOUTME: Core recorder library providing safe Rust API for Swift integration
// ABOUTME: Exposes screen recording functionality through FFI bridge

pub mod ffi;

use anyhow::Result;
use std::sync::Arc;
use std::sync::Mutex;

pub struct Recorder {
    inner: Arc<Mutex<RecorderInner>>,
}

struct RecorderInner {
    #[cfg(target_os = "macos")]
    capture: Option<ffi::SwiftCapture>,
    is_recording: bool,
}

impl Recorder {
    pub fn new() -> Self {
        Self {
            inner: Arc::new(Mutex::new(RecorderInner {
                #[cfg(target_os = "macos")]
                capture: None,
                is_recording: false,
            })),
        }
    }

    #[cfg(target_os = "macos")]
    pub fn start(
        &mut self,
        window_title: &str,
        width: u32,
        height: u32,
        bitrate: u32,
        output_path: &str,
    ) -> Result<()> {
        let mut inner = self.inner.lock().unwrap();
        
        if inner.is_recording {
            anyhow::bail!("Already recording");
        }

        let mut capture = ffi::create_capture_session();
        let success = ffi::start_capture(
            &mut capture,
            window_title,
            width,
            height,
            bitrate,
            output_path,
        );

        if success {
            inner.capture = Some(capture);
            inner.is_recording = true;
            Ok(())
        } else {
            anyhow::bail!(
                "Failed to start capture. \
                 Make sure the window title \"{}\" exists and that the app has \
                 Screen Recording permission (System Settings > Privacy & Security).",
                window_title
            )
        }
    }

    #[cfg(not(target_os = "macos"))]
    pub fn start(
        &mut self,
        _window_title: &str,
        _width: u32,
        _height: u32,
        _bitrate: u32,
        _output_path: &str,
    ) -> Result<()> {
        anyhow::bail!("Screen recording is only supported on macOS")
    }

    pub fn stop(&mut self) {
        let mut inner = self.inner.lock().unwrap();
        
        #[cfg(target_os = "macos")]
        if let Some(mut capture) = inner.capture.take() {
            ffi::stop_capture(&mut capture);
        }
        
        inner.is_recording = false;
    }

    pub fn is_recording(&self) -> bool {
        self.inner.lock().unwrap().is_recording
    }
}

impl Default for Recorder {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_recorder_creation() {
        let recorder = Recorder::new();
        assert!(!recorder.is_recording());
    }

    #[test]
    fn test_double_start_fails() {
        let mut recorder = Recorder::new();
        
        // First start should work (but will fail in test env without window)
        let _ = recorder.start("Test", 640, 480, 1000000, "/tmp/test.mp4");
        
        // Second start should fail if first succeeded
        if recorder.is_recording() {
            let result = recorder.start("Test", 640, 480, 1000000, "/tmp/test2.mp4");
            assert!(result.is_err());
        }
    }
}

#[cfg(test)]
#[path = "tests/ffi_smoke.rs"]
mod ffi_smoke;

#[cfg(test)]
#[cfg(target_os = "macos")]
#[path = "tests/ffi_integration.rs"]
mod ffi_integration;
</file>

<file path="recorder_core/Cargo.toml">
[package]
name = "recorder_core"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
anyhow = { workspace = true }
cxx = { workspace = true }

[build-dependencies]
cxx-build = "1.0"
cc = "1.0"

[dev-dependencies]
criterion = "0.5"

[[bench]]
name = "capture_bench"
harness = false
</file>

<file path=".github/workflows/ci.yml">
name: macOS CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  RUST_BACKTRACE: 1

jobs:
  test:
    name: Test on macOS
    runs-on: macos-14
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Swift
      uses: SwiftyLab/setup-swift@v1
      with:
        swift-version: "5.10"
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: "18"
        cache: 'npm'
    
    - name: Setup Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        components: rustfmt, clippy
    
    - name: Cache Rust dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
    
    - name: Swift tests
      run: |
        cd apple_capture
        swift test --parallel
    
    - name: Rust format check
      run: cargo fmt --all -- --check
    
    - name: Rust clippy
      run: cargo clippy --all-targets --all-features -- -D warnings
    
    - name: Rust tests
      run: cargo test --workspace --verbose
    
    - name: Bundle and integration tests
      run: |
        echo "Running bundle tests including rpath checks..."
        cargo test --workspace -- --ignored
    
    - name: Build release binary
      run: cargo build --release
    
    - name: Integration test - 3 second recording
      run: |
        # Grant screen recording permission in CI (simulated)
        # In real CI, this would need proper entitlements
        echo "Testing CLI..."
        ./target/release/recorder record --duration 3 --out /tmp/ci_test.mp4 || true
        
        # Check if binary exists and is reasonable size
        ls -la ./target/release/recorder
        SIZE=$(stat -f%z ./target/release/recorder)
        echo "Binary size: $SIZE bytes"
        
        # Ensure binary is under 40MB
        if [ $SIZE -gt 41943040 ]; then
          echo "Binary too large: $SIZE bytes (limit: 40MB)"
          exit 1
        fi
    
    - name: Node.js setup
      run: |
        npm ci
        cd extension-host
        npm ci
    
    - name: Node.js tests
      run: |
        npm run lint || true
        npm run typecheck || true
        npm test || true
    
    - name: Upload artifacts
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: recorder-macos
        path: target/release/recorder
    
    - name: Install cargo-bundle
      if: success()
      run: cargo install cargo-bundle
    
    - name: Bundle .app
      if: success()
      run: ./scripts/package_app.sh
    
    - name: Upload .app bundle
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: TFT-Recorder-app
        path: target/release/bundle/osx/TFT Recorder.app
        
  benchmark:
    name: Performance benchmarks
    runs-on: macos-14
    needs: test
    
    steps:
    - uses: actions/checkout@v4
    - uses: dtolnay/rust-toolchain@stable
    
    - name: Run benchmarks
      run: |
        cd recorder_core
        cargo bench --no-fail-fast || true
    
    - name: Check startup time
      run: |
        # Build optimized binary
        cargo build --release
        
        # Measure startup time
        START=$(date +%s.%N)
        timeout 1s ./target/release/recorder record --help
        END=$(date +%s.%N)
        
        # Calculate duration in milliseconds
        DURATION=$(echo "($END - $START) * 1000" | bc)
        echo "Startup time: ${DURATION}ms"
</file>

<file path="apple_capture/Package.swift">
// swift-tools-version: 5.10
// ABOUTME: Swift package for hardware-accelerated screen capture on macOS
// ABOUTME: Uses AVFoundation and VideoToolbox for minimal CPU overhead

import PackageDescription

let package = Package(
    name: "AppleCapture",
    platforms: [
        .macOS(.v12)
    ],
    products: [
        .library(
            name: "AppleCapture",
            type: .dynamic,
            targets: ["AppleCapture", "AppleCaptureC"]),
    ],
    targets: [
        .target(
            name: "AppleCapture",
            dependencies: [],
            path: "Sources/AppleCapture",
            swiftSettings: [
                .unsafeFlags(["-enable-library-evolution"])
            ]
        ),
        // Header-only C target so Cargo can dlopen symbols
        .target(
            name: "AppleCaptureC",
            dependencies: ["AppleCapture"],
            path: "Sources/AppleCaptureC",
            publicHeadersPath: "."
        ),
        .testTarget(
            name: "AppleCaptureTests",
            dependencies: ["AppleCapture"],
            path: "Sources/AppleCaptureTests"
        ),
    ]
)
</file>

<file path="recorder_cli/src/main.rs">
// ABOUTME: CLI entry point for TFT recorder with subcommands for recording and extension host
// ABOUTME: Provides user-friendly interface for screen capture and plugin management

use anyhow::Result;
use clap::{Parser, Subcommand};
use recorder_core::Recorder;
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};

pub mod gui;

#[derive(Parser)]
#[command(name = "recorder")]
#[command(about = "Ultra-light screen recorder for Team Fight Tactics", long_about = None)]
#[command(arg_required_else_help = false)]
struct Cli {
    #[command(subcommand)]
    command: Option<Commands>,
}

#[derive(Subcommand)]
enum Commands {
    /// Record TFT gameplay
    Record {
        /// Window title to capture
        #[arg(long, default_value = "Teamfight Tactics")]
        window: String,
        
        /// Video width in pixels
        #[arg(long, default_value = "1280")]
        width: u32,
        
        /// Video height in pixels
        #[arg(long, default_value = "720")]
        height: u32,
        
        /// Video bitrate in bits per second
        #[arg(long, default_value = "4000000")]
        bitrate: u32,
        
        /// Output file path (defaults to ~/Movies/TFT Recorder/TFT-timestamp.mp4)
        #[arg(long)]
        out: Option<String>,
        
        /// Duration in seconds (0 for manual stop)
        #[arg(long, default_value = "0")]
        duration: u32,
    },
    
    /// Start the extension host (internal use)
    Host {
        /// Port for gRPC communication
        #[arg(long, default_value = "0")]
        port: u16,
    },
    
    /// Run as daemon for background recording
    Daemon {
        /// Unix socket path for IPC
        #[arg(long, default_value = "/tmp/tft-recorder.sock")]
        socket: String,
    },
}

fn main() -> Result<()> {
    let cli = Cli::parse();
    
    match cli.command {
        Some(Commands::Record { window, width, height, bitrate, out, duration }) => {
            let output_path = out.unwrap_or_else(|| gui::get_default_output_path());
            record_command(window, width, height, bitrate, output_path, duration)
        }
        Some(Commands::Host { port }) => {
            host_command(port)
        }
        Some(Commands::Daemon { socket }) => {
            daemon_command(socket)
        }
        None => {
            // Launched from Finder - show GUI
            gui::launch()
        }
    }
}

fn record_command(
    window: String,
    width: u32,
    height: u32,
    bitrate: u32,
    out: String,
    duration: u32,
) -> Result<()> {
    // Ensure the output directory exists
    if let Some(parent) = std::path::Path::new(&out).parent() {
        std::fs::create_dir_all(parent)?;
    }
    println!("Starting recording...");
    println!("Window: {}", window);
    println!("Resolution: {}x{}", width, height);
    println!("Bitrate: {} bps", bitrate);
    println!("Output: {}", out);
    
    let mut recorder = Recorder::new();
    
    // Set up graceful shutdown
    let running = Arc::new(AtomicBool::new(true));
    let r = running.clone();
    
    ctrlc::set_handler(move || {
        println!("\nStopping recording...");
        r.store(false, Ordering::SeqCst);
    })?;
    
    // Start recording
    if let Err(e) = recorder.start(&window, width, height, bitrate, &out) {
        eprintln!("Error: {}", e);
        std::process::exit(1);
    }
    println!("Recording started. Press Ctrl+C to stop.");
    
    // Wait for duration or interrupt
    if duration > 0 {
        println!("Recording for {} seconds...", duration);
        let start = std::time::Instant::now();
        
        while running.load(Ordering::SeqCst) && start.elapsed().as_secs() < duration as u64 {
            std::thread::sleep(std::time::Duration::from_millis(100));
        }
    } else {
        // Wait for Ctrl+C
        while running.load(Ordering::SeqCst) {
            std::thread::sleep(std::time::Duration::from_millis(100));
        }
    }
    
    // Stop recording
    recorder.stop();
    println!("Recording saved to: {}", out);
    
    Ok(())
}

fn host_command(port: u16) -> Result<()> {
    println!("Starting extension host on port {}...", port);
    
    // In a real implementation, this would launch the Node.js process
    // For now, we'll just spawn it as a subprocess
    let status = std::process::Command::new("node")
        .arg("extension-host/dist/index.js")
        .arg("--port")
        .arg(port.to_string())
        .status()?;
    
    if !status.success() {
        anyhow::bail!("Extension host failed to start");
    }
    
    Ok(())
}

fn daemon_command(socket: String) -> Result<()> {
    println!("Starting recorder daemon on socket: {}", socket);
    
    // Set up the async runtime for gRPC
    let runtime = tokio::runtime::Runtime::new()?;
    
    runtime.block_on(async {
        // In a real implementation, this would start the gRPC server
        println!("Daemon started. Listening for commands...");
        
        // Keep running until interrupted
        tokio::signal::ctrl_c().await?;
        println!("Daemon shutting down...");
        
        Ok::<(), anyhow::Error>(())
    })?;
    
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use clap::CommandFactory;

    #[test]
    fn verify_cli() {
        Cli::command().debug_assert();
    }
    
    #[test]
    fn test_default_args() {
        let cli = Cli::parse_from(vec!["recorder", "record"]);
        match cli.command {
            Some(Commands::Record { window, width, height, bitrate, out, duration }) => {
                assert_eq!(window, "Teamfight Tactics");
                assert_eq!(width, 1280);
                assert_eq!(height, 720);
                assert_eq!(bitrate, 4000000);
                assert!(out.is_none());
                assert_eq!(duration, 0);
            }
            _ => panic!("Expected Record command"),
        }
    }
}
</file>

<file path="recorder_core/src/ffi.rs">
// ABOUTME: FFI bridge between Rust and Swift using manual C bindings
// ABOUTME: Provides low-level interface for cross-language communication

use std::ffi::{c_char, c_void, CString};

#[repr(transparent)]
pub struct SwiftCapture {
    ptr: *mut c_void,
}

// Ensure SwiftCapture is Send + Sync for thread safety
unsafe impl Send for SwiftCapture {}
unsafe impl Sync for SwiftCapture {}

#[cfg(target_os = "macos")]
extern "C" {
    fn swift_capture_create() -> *mut c_void;
    fn swift_capture_destroy(ptr: *mut c_void);
    fn swift_capture_start(
        ptr: *mut c_void,
        window_title: *const c_char,
        width: u32,
        height: u32,
        bitrate: u32,
        output_path: *const c_char,
    ) -> bool;
    fn swift_capture_stop(ptr: *mut c_void);
}

#[cfg(target_os = "macos")]
pub fn create_capture_session() -> SwiftCapture {
    let ptr = unsafe { swift_capture_create() };
    assert!(!ptr.is_null(), "Failed to create Swift capture session");
    SwiftCapture { ptr }
}

#[cfg(target_os = "macos")]
pub fn start_capture(
    cap: &mut SwiftCapture,
    window_title: &str,
    width: u32,
    height: u32,
    bitrate: u32,
    output_path: &str,
) -> bool {
    let c_title = CString::new(window_title).expect("Invalid window title");
    let c_path = CString::new(output_path).expect("Invalid output path");
    
    unsafe {
        swift_capture_start(
            cap.ptr,
            c_title.as_ptr(),
            width,
            height,
            bitrate,
            c_path.as_ptr(),
        )
    }
}

#[cfg(target_os = "macos")]
pub fn stop_capture(cap: &mut SwiftCapture) {
    unsafe { swift_capture_stop(cap.ptr) }
}

#[cfg(target_os = "macos")]
impl Drop for SwiftCapture {
    fn drop(&mut self) {
        if !self.ptr.is_null() {
            unsafe { swift_capture_destroy(self.ptr) }
        }
    }
}

// Non-macOS stubs
#[cfg(not(target_os = "macos"))]
pub fn create_capture_session() -> SwiftCapture {
    SwiftCapture { ptr: std::ptr::null_mut() }
}

#[cfg(not(target_os = "macos"))]
pub fn start_capture(
    _cap: &mut SwiftCapture,
    _window_title: &str,
    _width: u32,
    _height: u32,
    _bitrate: u32,
    _output_path: &str,
) -> bool {
    false
}

#[cfg(not(target_os = "macos"))]
pub fn stop_capture(_cap: &mut SwiftCapture) {}

#[cfg(not(target_os = "macos"))]
impl Drop for SwiftCapture {
    fn drop(&mut self) {}
}
</file>

<file path="scripts/package_app.sh">
#!/usr/bin/env bash
# ABOUTME: Script to package the TFT Recorder as a macOS .app bundle
# ABOUTME: Handles building, bundling, and copying the Swift dylib

set -euo pipefail

echo "🔨 Building TFT Recorder.app..."

# Build the release binary and bundle it
cargo bundle --bin recorder --release

# The bundle might be named differently, check both possibilities
if [ -d "target/release/bundle/osx/TFT Recorder.app" ]; then
    APP="target/release/bundle/osx/TFT Recorder.app"
elif [ -d "target/release/bundle/osx/recorder_cli.app" ]; then
    APP="target/release/bundle/osx/recorder_cli.app"
    # Rename to the expected name
    mv "$APP" "target/release/bundle/osx/TFT Recorder.app"
    APP="target/release/bundle/osx/TFT Recorder.app"
    # Delete the stale bundle to avoid confusion
    rm -rf "target/release/bundle/osx/recorder_cli.app"
else
    echo "❌ Error: Could not find app bundle"
    exit 1
fi

DYLIB="apple_capture/.build/$(uname -m)-apple-macosx/release/libAppleCapture.dylib"

# Re-build the Swift package so the dylib is always fresh
echo "🔨 Building Swift package (release)..."
(cd apple_capture && swift build -c release)

# Frameworks and Resources folders
mkdir -p "$APP/Contents/Frameworks" "$APP/Contents/Resources"

if [ -f "resources/tft.icns" ]; then
    echo "📦 Copying app icon..."
    cp "resources/tft.icns" "$APP/Contents/Resources/"
fi

# Copy the Swift dynamic library into the app bundle
if [ -f "$DYLIB" ]; then
    echo "📦 Copying libAppleCapture.dylib to app bundle..."
    cp "$DYLIB" "$APP/Contents/Frameworks/"
else
    echo "❌ libAppleCapture.dylib not found at $DYLIB"
    exit 1
fi

# Fix the library references to use @rpath correctly
if command -v install_name_tool &> /dev/null; then
    echo "🔧 Updating library paths..."
    # Set the dylib's install name to @rpath-relative
    install_name_tool -id "@rpath/libAppleCapture.dylib" \
        "$APP/Contents/Frameworks/libAppleCapture.dylib"
    
    # Ensure the binary references the dylib via @rpath
    install_name_tool -change "@rpath/libAppleCapture.dylib" \
        "@rpath/libAppleCapture.dylib" \
        "$APP/Contents/MacOS/recorder"
fi

echo "✅ Created $APP"
echo ""
echo "To run the app:"
echo "  open \"$APP\""
echo ""
echo "First run will prompt for Screen Recording permission."
</file>

<file path="recorder_cli/Cargo.toml">
[package]
name = "recorder_cli"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
build = "build.rs"

[[bin]]
name = "recorder"
path = "src/main.rs"

[dependencies]
recorder_core = { path = "../recorder_core" }
anyhow = { workspace = true }
clap = { workspace = true }
tokio = { workspace = true }
ctrlc = "3.4"
eframe = "0.27"
egui = "0.27"
chrono = "0.4"
shellexpand = "3.1"
dirs = "5.0"

# Bundle metadata for cargo-bundle to generate macOS .app
[package.metadata.bundle]
name = "TFT Recorder"
identifier = "com.tftreplay.recorder"
icon = ["../resources/tft.icns"]
version = "0.1.0"
resources = []
copyright = "Copyright (c) 2024 TFT Recorder Contributors"
category = "public.app-category.video"
short_description = "Screen recorder for Team Fight Tactics"
long_description = "Ultra-light screen recorder optimized for Team Fight Tactics gameplay capture on macOS."

[package.metadata.bundle.macos]
minimum_system_version = "12.0"
info_plist_path = "../mac_app/Info.plist"
entitlements_path = "../mac_app/entitlements.plist"
frameworks = [
    "AVFoundation.framework",
    "CoreMedia.framework", 
    "CoreVideo.framework",
    "VideoToolbox.framework",
    "CoreGraphics.framework"
]
</file>

<file path="recorder_core/build.rs">
// ABOUTME: Build script for linking Swift capture library with Rust
// ABOUTME: Handles platform-specific compilation and linking requirements

#[cfg(target_os = "macos")]
fn main() {
    use std::{path::PathBuf, process::Command};

    // 1. Build Swift package in release mode
    let manifest_dir = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
    let project_root = manifest_dir
        .parent()
        .expect("Failed to get project root");
    let swift_pkg = project_root.join("apple_capture");
    
    println!("cargo:warning=Building Swift package at {:?}", swift_pkg);
    
    let output = Command::new("swift")
        .args(["build", "-c", "release", "--package-path"])
        .arg(&swift_pkg)
        .output()
        .expect("Failed to run swift build");
        
    if !output.status.success() {
        eprintln!("Swift build failed!");
        eprintln!("stdout: {}", String::from_utf8_lossy(&output.stdout));
        eprintln!("stderr: {}", String::from_utf8_lossy(&output.stderr));
        panic!("Swift build failed");
    }

    // 2. Tell Cargo where to find the compiled .dylib
    let lib_dir = swift_pkg.join(".build/arm64-apple-macosx/release");
    println!("cargo:rustc-link-search=native={}", lib_dir.display());
    println!("cargo:rustc-link-lib=dylib=AppleCapture");
    
    // Add rpath so the binary can find the library at runtime
    // Use @executable_path/../Frameworks for app bundles
    println!("cargo:rustc-link-arg=-Wl,-rpath,@executable_path/../Frameworks");
    // Also add the development path for non-bundled usage
    println!("cargo:rustc-link-arg=-Wl,-rpath,{}", lib_dir.display());

    // 3. Link system frameworks
    for fw in ["AVFoundation", "CoreMedia", "CoreVideo", "VideoToolbox", "CoreGraphics"] {
        println!("cargo:rustc-link-lib=framework={}", fw);
    }

    // 4. Rebuild if Swift code changed
    println!("cargo:rerun-if-changed=../apple_capture/Sources");
}

#[cfg(not(target_os = "macos"))]
fn main() {
    // No-op on other platforms
}
</file>

</files>
